{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72ad2f51102c483bbf51de2b9af49ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f665e8274ef34fd38863e53d0411a402",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84641c3ed8c149719b7122c27d8923dd",
              "IPY_MODEL_0a947e7df301416ebe172f5b236e0be7"
            ]
          }
        },
        "f665e8274ef34fd38863e53d0411a402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84641c3ed8c149719b7122c27d8923dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53b4821201194a69a7d3ea0a33f02bbb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77261ba6e48849af9a4ec2e92da5df43"
          }
        },
        "0a947e7df301416ebe172f5b236e0be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2bea2db04054698bba58dac46de7109",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2554/? [13:29&lt;00:00,  3.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ef6699aee1045d98602d69b73a95a06"
          }
        },
        "53b4821201194a69a7d3ea0a33f02bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77261ba6e48849af9a4ec2e92da5df43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2bea2db04054698bba58dac46de7109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ef6699aee1045d98602d69b73a95a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4af0788bc51a4e2897a6672c8cb4cefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a2dba9eb49c4445a5d9fe4df799cb9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_175274caee524338b8fcda9c95a1b033",
              "IPY_MODEL_1dafa5a65b6f40f984a59297f189d637"
            ]
          }
        },
        "3a2dba9eb49c4445a5d9fe4df799cb9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "175274caee524338b8fcda9c95a1b033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29b5b41ba528424282c126ffebd341a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb4403211ab34a1ebefb5d64609cc74d"
          }
        },
        "1dafa5a65b6f40f984a59297f189d637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4150beee67924197b2c70f76097e11d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2554/? [13:24&lt;00:00,  3.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_145cd6882a7d44c49210f4f7315184ac"
          }
        },
        "29b5b41ba528424282c126ffebd341a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb4403211ab34a1ebefb5d64609cc74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4150beee67924197b2c70f76097e11d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "145cd6882a7d44c49210f4f7315184ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicostanw/NLP_Toxic_Comment_Classification/blob/main/NLP_Project_Dimanche.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo166gvu92ie"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string \n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O35F-MQCD7Y",
        "outputId": "b613cec7-4ede-4142-f3c4-c19e88546782"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evIV9EJHCGVT",
        "outputId": "4ce695ef-0791-4e59-ca0c-8c50929a9182"
      },
      "source": [
        "%cd drive/MyDrive/NLP project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34pD9DTYCOXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1422fae-d780-42a3-c2d7-dcee0f2859de"
      },
      "source": [
        "train = pd.read_csv('train.csv', sep=',')\n",
        "print(train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159571, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEMsi-MqCLSy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "58f400a5-3f4a-4870-c1f9-17f89b18f6fa"
      },
      "source": [
        "train.head(15)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0005300084f90edc</td>\n",
              "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>00054a5e18b50dd4</td>\n",
              "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0005c987bdfc9d4b</td>\n",
              "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0006f16e4e9f292e</td>\n",
              "      <td>Before you start throwing accusations and warn...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>00070ef96486d6f9</td>\n",
              "      <td>Oh, and the girl above started her arguments w...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  ... identity_hate\n",
              "0   0000997932d777bf  ...             0\n",
              "1   000103f0d9cfb60f  ...             0\n",
              "2   000113f07ec002fd  ...             0\n",
              "3   0001b41b1c6bb37e  ...             0\n",
              "4   0001d958c54c6e35  ...             0\n",
              "5   00025465d4725e87  ...             0\n",
              "6   0002bcb3da6cb337  ...             0\n",
              "7   00031b1e95af7921  ...             0\n",
              "8   00037261f536c51d  ...             0\n",
              "9   00040093b2687caa  ...             0\n",
              "10  0005300084f90edc  ...             0\n",
              "11  00054a5e18b50dd4  ...             0\n",
              "12  0005c987bdfc9d4b  ...             0\n",
              "13  0006f16e4e9f292e  ...             0\n",
              "14  00070ef96486d6f9  ...             0\n",
              "\n",
              "[15 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD34nUPOCQWo"
      },
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "#Tokenization, on rÃ©duit les phrases en bouts simples\n",
        "\n",
        "def clean_text(text):\n",
        "  text=text.lower()  #Met en minuscules\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')   #Enleve les liens \n",
        "  text=url_pattern.sub(r'', text)\n",
        "  text=re.sub(r'\\d+', '',text)    #Enleve les nbs\n",
        "  translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))    #Enleve poncutation \n",
        "  text=text.translate(translator)\n",
        "  text=re.sub(r'\\n',' ',text)   #enleve les /n\n",
        "  text= re.sub(' +', ' ', text)    #enleve les trop grands espaces \n",
        "  return(text.strip())   #Clean les bords"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeCWfZtYCScd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a27a04-5307-4b77-94f6-e8313c7f680d"
      },
      "source": [
        "X=train[\"comment_text\"].apply(clean_text)\n",
        "X.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    explanation why the edits made under my userna...\n",
              "1    d aww he matches this background colour i m se...\n",
              "2    hey man i m really not trying to edit war it s...\n",
              "3    more i can t make any real suggestions on impr...\n",
              "4    you sir are my hero any chance you remember wh...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1BczqXbCUEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecc0530-3d64-417b-c19e-73c0f592a355"
      },
      "source": [
        "y=train[train.columns[2:]].apply(lambda x:np.array(list(x)),axis=1)\n",
        "print(y) \n",
        "print(len(y))\n",
        "num_class=y[0].size\n",
        "print(num_class)\n",
        "print(y.sum())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         [0, 0, 0, 0, 0, 0]\n",
            "1         [0, 0, 0, 0, 0, 0]\n",
            "2         [0, 0, 0, 0, 0, 0]\n",
            "3         [0, 0, 0, 0, 0, 0]\n",
            "4         [0, 0, 0, 0, 0, 0]\n",
            "                 ...        \n",
            "159566    [0, 0, 0, 0, 0, 0]\n",
            "159567    [0, 0, 0, 0, 0, 0]\n",
            "159568    [0, 0, 0, 0, 0, 0]\n",
            "159569    [0, 0, 0, 0, 0, 0]\n",
            "159570    [0, 0, 0, 0, 0, 0]\n",
            "Length: 159571, dtype: object\n",
            "159571\n",
            "6\n",
            "[15294  1595  8449   478  7877  1405]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYfFxb6GCWCo"
      },
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "counter = Counter()\n",
        "for text in X:\n",
        "  counter.update(tokenizer(text))\n",
        "vocab = Vocab(counter, min_freq=3)   #Le vocab qui apparait au moins 3 fois"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-P2VgaACX_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0840d8c-a854-43da-b9da-3d91a54eb7df"
      },
      "source": [
        "vocab_size=len(vocab)\n",
        "print(vocab_size)  #En tout on a 59 868 mots qui apparaissent au moins 3 fois"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-RaSX5eCZo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51206dc6-d8ef-43e3-a42d-5ee27efd825f"
      },
      "source": [
        "max_len=X.map(lambda x:len(tokenizer(x))).max()    #Le plus long texte\n",
        "print(max_len)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW46ILayCbXU"
      },
      "source": [
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9__V9yFCe1x"
      },
      "source": [
        "class ToxicCommentDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, X,y):\n",
        "\n",
        "        self.X =X\n",
        "        self.y =y\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "       \n",
        "        return (self.X.iloc[idx],self.y.iloc[idx])\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    vectorized_seqs=[]\n",
        "    list_label=[]\n",
        "    for text , label in batch:\n",
        "      vectorized_seqs.append(text_pipeline(text))\n",
        "      list_label.append(label)\n",
        "      \n",
        "    seq_lengths=list(map(len, vectorized_seqs))\n",
        "    seq_tensor=torch.ones(size=(len(batch),max_len),dtype=torch.int64)\n",
        "    for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "      seq_tensor[idx, :seqlen] = torch.tensor(seq,dtype=torch.int64)\n",
        "    \n",
        "        \n",
        "    return seq_tensor.to(device),torch.tensor(list_label,dtype=torch.int64).to(device)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKQFysffCisP"
      },
      "source": [
        "from torch import nn\n",
        "from torch import autograd\n",
        "from torch.nn import functional as F\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim,hidden_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "      \n",
        "        self.hidden_dim=hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size,embed_dim, padding_idx=1)\n",
        "        self.lstm = nn.LSTM(input_size=embed_dim,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        #self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc = nn.Linear(2*hidden_dim,num_class)\n",
        "       # self.hidden = self.init_hidden()\n",
        "\n",
        "    '''def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return (autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim)),   \n",
        "                autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim))) '''\n",
        "\n",
        "    def forward(self, text):\n",
        "        embed_text= self.embedding(text)\n",
        "        lstm_out,(hn,cn) = self.lstm(embed_text)\n",
        "        x=torch.cat((hn[0,:,:],hn[1,:,:]),1)\n",
        "        return torch.sigmoid(self.fc(x))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXbFL9gnCmZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4288dd-4dec-4e0e-97d5-2f1dfccb2b35"
      },
      "source": [
        "toxic_train=ToxicCommentDataset(X_train,y_train)\n",
        "dataloaders = DataLoader(toxic_train, batch_size=8, shuffle=False,collate_fn=collate_batch)\n",
        "print(dataloaders)\n",
        "\n",
        "criterion1 = nn.BCELoss()\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "\n",
        "for i,(u,l) in enumerate(dataloaders):\n",
        "  \n",
        "  outputs = model(u)\n",
        "  preds2=torch.where(outputs<0.5,0,1).float()\n",
        "  #print((preds2==l).float().mean(axis=1).mean())\n",
        "  print((preds2==l).float())\n",
        "  print((preds2==l))\n",
        "  print(l,preds2)\n",
        "  loss=0\n",
        "  if i==0:\n",
        "    break\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f9d9bcc4150>\n",
            "tensor([[1., 0., 0., 1., 1., 0.],\n",
            "        [1., 0., 1., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 0., 1., 0., 1.],\n",
            "        [1., 0., 0., 0., 1., 0.],\n",
            "        [0., 1., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 1.]], device='cuda:0')\n",
            "tensor([[ True, False, False,  True,  True, False],\n",
            "        [ True, False,  True, False,  True, False],\n",
            "        [ True, False, False, False, False, False],\n",
            "        [ True, False, False, False,  True,  True],\n",
            "        [False, False, False,  True, False,  True],\n",
            "        [ True, False, False, False,  True, False],\n",
            "        [False,  True,  True, False, False, False],\n",
            "        [False, False, False, False,  True,  True]], device='cuda:0')\n",
            "tensor([[0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0]], device='cuda:0') tensor([[0., 1., 1., 0., 0., 1.],\n",
            "        [0., 1., 0., 1., 0., 1.],\n",
            "        [0., 1., 1., 1., 1., 1.],\n",
            "        [0., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 1., 0.],\n",
            "        [0., 1., 1., 1., 0., 1.],\n",
            "        [0., 1., 1., 1., 0., 1.],\n",
            "        [1., 1., 1., 1., 0., 0.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQZAOz1_CoaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70cde8a-3560-4830-a714-914569b3090d"
      },
      "source": [
        "x=np.arange(40).reshape(2,2,10)\n",
        "print(x.shape)\n",
        "print(x[0,:,:],x[1,:,:])\n",
        "print(np.concatenate((x[0,:,:],x[1,:,:]),axis=1).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2, 10)\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29]\n",
            " [30 31 32 33 34 35 36 37 38 39]]\n",
            "(2, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I9WrOZiPyuR"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from numba import cuda\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tqdm.notebook as tq"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4naqefFBs3u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "997ffd26-6a35-4392-af9b-8c6842e8845e"
      },
      "source": [
        "#Now we set our training function \n",
        "def train_model(model,X,y, optimizer, batch_size=10,num_epochs=9):\n",
        "    \n",
        "    X_train,X_val,y_train,y_val=train_test_split(X,y,random_state=5,test_size=0.2)\n",
        "    toxic_train=ToxicCommentDataset(X_train,y_train)\n",
        "    trainloader = DataLoader(ToxicCommentDataset(X_train,y_train), batch_size=batch_size, shuffle=True,collate_fn=collate_batch)\n",
        "    valloader   = DataLoader(ToxicCommentDataset(X_val,y_val), batch_size=1000, shuffle=True,collate_fn=collate_batch)\n",
        "    criterion=nn.BCELoss(reduction='sum')\n",
        "    since = time.time()\n",
        "   \n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        \n",
        "        running_train_loss = 0.0\n",
        "        \n",
        "        \n",
        "        model.train()\n",
        "        # Iterate over data.\n",
        "        for j,(inputs, labels) in tq.tqdm(enumerate(trainloader),1):\n",
        "        \n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "              \n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                outputs = model(inputs)\n",
        "                \n",
        "                loss = criterion(outputs, labels.float())\n",
        "                \n",
        "                      #running_corrects += torch.sum(preds == labels.data[:,z])\n",
        "                    # backward + optimize only if in training phase\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "          \n",
        "                running_train_loss += loss.item()\n",
        "             \n",
        "                if j%510==0:\n",
        "                  model.eval()  \n",
        "                  map=0 \n",
        "                  i=0\n",
        "                  running_val_loss = 0.0\n",
        "                  with torch.no_grad():   \n",
        "                    for val_inp,val_lab in valloader:\n",
        "                 \n",
        "                      val_out = model(val_inp)\n",
        "                      loss = criterion(val_out, val_lab.float())\n",
        "                      running_val_loss += loss.item() \n",
        "                      preds=torch.where(val_out<0.5,0,1)\n",
        "            \n",
        "                      map+=(preds==val_lab).float().mean()\n",
        "                      i+=1\n",
        "                  runnig_val_loss=running_val_loss/(len(valloader.dataset)*num_class)\n",
        "                  map=map/i\n",
        "                  print(f\"Epoch[{epoch}/{num_epochs}],batch[{j}/{len(trainloader.dataset)//batch_size}]: val_loss={running_val_loss:.3f}\",\n",
        "                        f\"mean average precision={map:.3f}\")\n",
        "                  model.train()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "          time_elapsed // 60, time_elapsed % 60))\n",
        "# deep copy the model\n",
        "''' epoch_acc > best_acc:\n",
        "best_acc = epoch_acc\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "model_file = model_name + '/model_' + str(epoch) + '.pth'\n",
        "print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
        "print()'''\n",
        "    \n",
        "       \n",
        "#print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "# load best model weights\n",
        "#model.load_state_dict(best_model_wts)\n",
        "    \n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" epoch_acc > best_acc:\\nbest_acc = epoch_acc\\nbest_model_wts = copy.deepcopy(model.state_dict())\\nmodel_file = model_name + '/model_' + str(epoch) + '.pth'\\nprint('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\\nprint()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXWGZzW3j33g",
        "outputId": "1e152fe9-5d05-4a68-8e9f-2a1399406a82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size=50\n",
        "_,_,y_t,_=train_test_split(X,y,random_state=5,test_size=0.2)\n",
        "(((y_t.size)//batch_size)-1)//5"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "510"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5A5M8fEgGE5"
      },
      "source": [
        "batch_size=50\n",
        "model=TextClassificationModel(vocab_size,100,100,num_class).to(device)\n",
        "optimizer=optim.Adam(model.parameters(),lr=1e-3)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33LkOcIllyVC",
        "outputId": "f9c2749a-811b-4517-8931-bec3b7b8ad2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "72ad2f51102c483bbf51de2b9af49ef7",
            "f665e8274ef34fd38863e53d0411a402",
            "84641c3ed8c149719b7122c27d8923dd",
            "0a947e7df301416ebe172f5b236e0be7",
            "53b4821201194a69a7d3ea0a33f02bbb",
            "77261ba6e48849af9a4ec2e92da5df43",
            "d2bea2db04054698bba58dac46de7109",
            "0ef6699aee1045d98602d69b73a95a06",
            "4af0788bc51a4e2897a6672c8cb4cefb",
            "3a2dba9eb49c4445a5d9fe4df799cb9d",
            "175274caee524338b8fcda9c95a1b033",
            "1dafa5a65b6f40f984a59297f189d637",
            "29b5b41ba528424282c126ffebd341a5",
            "bb4403211ab34a1ebefb5d64609cc74d",
            "4150beee67924197b2c70f76097e11d9",
            "145cd6882a7d44c49210f4f7315184ac"
          ]
        }
      },
      "source": [
        "train_model(model,X,y, optimizer, batch_size=50,num_epochs=2)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72ad2f51102c483bbf51de2b9af49ef7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch[1/2],batch[0/2552]: val_loss=131801.217 mean average precision=0.561\n",
            "Epoch[1/2],batch[510/2552]: val_loss=17147.348 mean average precision=0.971\n",
            "Epoch[1/2],batch[1020/2552]: val_loss=14574.624 mean average precision=0.978\n",
            "Epoch[1/2],batch[1530/2552]: val_loss=12368.442 mean average precision=0.978\n",
            "Epoch[1/2],batch[2040/2552]: val_loss=11390.682 mean average precision=0.980\n",
            "Epoch[1/2],batch[2550/2552]: val_loss=10610.766 mean average precision=0.981\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4af0788bc51a4e2897a6672c8cb4cefb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch[2/2],batch[0/2552]: val_loss=10898.373 mean average precision=0.981\n",
            "Epoch[2/2],batch[510/2552]: val_loss=10468.121 mean average precision=0.981\n",
            "Epoch[2/2],batch[1020/2552]: val_loss=10066.409 mean average precision=0.981\n",
            "Epoch[2/2],batch[1530/2552]: val_loss=10039.264 mean average precision=0.981\n",
            "Epoch[2/2],batch[2040/2552]: val_loss=14084.244 mean average precision=0.977\n",
            "Epoch[2/2],batch[2550/2552]: val_loss=10447.277 mean average precision=0.981\n",
            "\n",
            "Training complete in 26m 54s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}