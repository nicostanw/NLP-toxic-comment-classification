{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyNdHF0s3QNtWnrK9OM2ix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicostanw/NLP_Toxic_Comment_Classification/blob/main/NLP_Project_Dimanche.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo166gvu92ie"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string \n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O35F-MQCD7Y",
        "outputId": "3e6e763b-e06b-4c56-b69c-a8235d07d969"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evIV9EJHCGVT",
        "outputId": "20932dd6-f1e6-42f5-cb76-a0e6be3bf8d0"
      },
      "source": [
        "%cd drive/MyDrive/NLP"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34pD9DTYCOXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7b4103-ac2b-4a26-a49c-ac1e595ef9d7"
      },
      "source": [
        "train = pd.read_csv('train.csv', sep=',')\n",
        "print(train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159571, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEMsi-MqCLSy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "274c0b97-6482-40d1-800f-e6ee175d8ffa"
      },
      "source": [
        "train.head(15)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0005300084f90edc</td>\n",
              "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>00054a5e18b50dd4</td>\n",
              "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0005c987bdfc9d4b</td>\n",
              "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0006f16e4e9f292e</td>\n",
              "      <td>Before you start throwing accusations and warn...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>00070ef96486d6f9</td>\n",
              "      <td>Oh, and the girl above started her arguments w...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  ... identity_hate\n",
              "0   0000997932d777bf  ...             0\n",
              "1   000103f0d9cfb60f  ...             0\n",
              "2   000113f07ec002fd  ...             0\n",
              "3   0001b41b1c6bb37e  ...             0\n",
              "4   0001d958c54c6e35  ...             0\n",
              "5   00025465d4725e87  ...             0\n",
              "6   0002bcb3da6cb337  ...             0\n",
              "7   00031b1e95af7921  ...             0\n",
              "8   00037261f536c51d  ...             0\n",
              "9   00040093b2687caa  ...             0\n",
              "10  0005300084f90edc  ...             0\n",
              "11  00054a5e18b50dd4  ...             0\n",
              "12  0005c987bdfc9d4b  ...             0\n",
              "13  0006f16e4e9f292e  ...             0\n",
              "14  00070ef96486d6f9  ...             0\n",
              "\n",
              "[15 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD34nUPOCQWo"
      },
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "#Tokenization, on réduit les phrases en bouts simples\n",
        "\n",
        "def clean_text(text):\n",
        "  text=text.lower()  #Met en minuscules\n",
        "  url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')   #Enleve les liens \n",
        "  text=url_pattern.sub(r'', text)\n",
        "  text=re.sub(r'\\d+', '',text)    #Enleve les nbs\n",
        "  translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))    #Enleve poncutation \n",
        "  text=text.translate(translator)\n",
        "  text=re.sub(r'\\n',' ',text)   #enleve les /n\n",
        "  text= re.sub(' +', ' ', text)    #enleve les trop grands espaces \n",
        "  return(text.strip())   #Clean les bords"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeCWfZtYCScd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a2d9e5-178e-4ec2-ac9c-a140bad2b3b2"
      },
      "source": [
        "X_train=train[\"comment_text\"].apply(clean_text)\n",
        "X_train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    explanation why the edits made under my userna...\n",
              "1    d aww he matches this background colour i m se...\n",
              "2    hey man i m really not trying to edit war it s...\n",
              "3    more i can t make any real suggestions on impr...\n",
              "4    you sir are my hero any chance you remember wh...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1BczqXbCUEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e353fbf-5831-4e06-bb7f-29d15b2e062e"
      },
      "source": [
        "y_train=train[train.columns[2:]].apply(lambda x:np.array(list(x)),axis=1)\n",
        "print(y_train) \n",
        "print(len(y_train))\n",
        "num_class=y_train[0].size\n",
        "print(num_class)\n",
        "print(y_train.sum())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         [0, 0, 0, 0, 0, 0]\n",
            "1         [0, 0, 0, 0, 0, 0]\n",
            "2         [0, 0, 0, 0, 0, 0]\n",
            "3         [0, 0, 0, 0, 0, 0]\n",
            "4         [0, 0, 0, 0, 0, 0]\n",
            "                 ...        \n",
            "159566    [0, 0, 0, 0, 0, 0]\n",
            "159567    [0, 0, 0, 0, 0, 0]\n",
            "159568    [0, 0, 0, 0, 0, 0]\n",
            "159569    [0, 0, 0, 0, 0, 0]\n",
            "159570    [0, 0, 0, 0, 0, 0]\n",
            "Length: 159571, dtype: object\n",
            "159571\n",
            "6\n",
            "[15294  1595  8449   478  7877  1405]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYfFxb6GCWCo"
      },
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "counter = Counter()\n",
        "for text in X_train:\n",
        "  counter.update(tokenizer(text))\n",
        "vocab = Vocab(counter, min_freq=3)   #Le vocab qui apparait au moins 3 fois"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-P2VgaACX_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89e47d0-9049-4a34-e696-95a68f7cddf0"
      },
      "source": [
        "vocab_size=len(vocab)\n",
        "print(vocab_size)  #En tout on a 59 868 mots qui apparaissent au moins 3 fois"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-RaSX5eCZo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ac2ae8-f66d-47d8-ec2b-6bb820b27dd6"
      },
      "source": [
        "max_len=X_train.map(lambda x:len(tokenizer(x))).max()    #Le plus long texte\n",
        "print(max_len)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW46ILayCbXU"
      },
      "source": [
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9__V9yFCe1x"
      },
      "source": [
        "class ToxicCommentDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, X,y):\n",
        "\n",
        "        self.X =X\n",
        "        self.y =y\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "       \n",
        "        return (self.X[idx],self.y[idx])\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "    vectorized_seqs=[]\n",
        "    list_label=[]\n",
        "    for text , label in batch:\n",
        "      vectorized_seqs.append(text_pipeline(text))\n",
        "      list_label.append(label)\n",
        "      \n",
        "    seq_lengths=list(map(len, vectorized_seqs))\n",
        "    seq_tensor=torch.ones(size=(len(batch),max_len),dtype=torch.int64)\n",
        "    for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "      seq_tensor[idx, :seqlen] = torch.tensor(seq,dtype=torch.int64)\n",
        "    \n",
        "        \n",
        "    return seq_tensor.to(device),torch.tensor(list_label,dtype=torch.int64).to(device)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKQFysffCisP"
      },
      "source": [
        "from torch import nn\n",
        "from torch import autograd\n",
        "from torch.nn import functional as F\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim,hidden_dim, num_class,batch_size):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.batch_size=batch_size\n",
        "        self.hidden_dim=hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding( vocab_size,embed_dim, padding_idx=1)\n",
        "        self.lstm = nn.LSTM(input_size=embed_dim,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        #self.drop = nn.Dropout(p=0.5)\n",
        "\n",
        "        self.fc = nn.Linear(2*hidden_dim,num_class)\n",
        "       # self.hidden = self.init_hidden()\n",
        "\n",
        "    '''def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return (autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim)),   \n",
        "                autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim))) '''\n",
        "\n",
        "    def forward(self, text):\n",
        "        embed_text= self.embedding(text)\n",
        "        lstm_out,(hn,cn) = self.lstm(embed_text)\n",
        "        x=torch.cat((hn[0,:,:],hn[1,:,:]),1)\n",
        "        return torch.sigmoid(self.fc(x))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icm3mmYICkqM"
      },
      "source": [
        "model=TextClassificationModel(vocab_size,100,50,num_class,8)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiCvoLVAMq_n",
        "outputId": "ebf2a7ec-8c5d-4ae3-ada7-d58ae63e4975"
      },
      "source": [
        "toxic_train.X_\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         explanation why the edits made under my userna...\n",
              "1         d aww he matches this background colour i m se...\n",
              "2         hey man i m really not trying to edit war it s...\n",
              "3         more i can t make any real suggestions on impr...\n",
              "4         you sir are my hero any chance you remember wh...\n",
              "                                ...                        \n",
              "159566    and for the second time of asking when your vi...\n",
              "159567    you should be ashamed of yourself that is a ho...\n",
              "159568    spitzer umm theres no actual article for prost...\n",
              "159569    and it looks like it was actually you who put ...\n",
              "159570    and i really don t think you understand i came...\n",
              "Name: comment_text, Length: 159571, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXbFL9gnCmZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbf0276-8599-4acb-d582-e213a5dad97f"
      },
      "source": [
        "toxic_train=ToxicCommentDataset(X_train,y_train)\n",
        "dataloaders = DataLoader(toxic_train, batch_size=8, shuffle=False,collate_fn=collate_batch)\n",
        "print(dataloaders)\n",
        "\n",
        "criterion1 = nn.BCELoss()\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "\n",
        "for i,(u,l) in enumerate(dataloaders):\n",
        "  \n",
        "  outputs = model(u)\n",
        "  preds2=torch.where(outputs<0.5,0,1).float()\n",
        "  #print((preds2==l).float().mean(axis=1).mean())\n",
        "  print((preds2==l).float())\n",
        "  print((preds2==l))\n",
        "  print(l,preds2)\n",
        "  loss=0\n",
        "  if i==0:\n",
        "    break\n"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f94b7551710>\n",
            "tensor([[1., 1., 0., 1., 1., 1.],\n",
            "        [1., 0., 0., 1., 0., 1.],\n",
            "        [1., 1., 0., 1., 1., 1.],\n",
            "        [1., 1., 0., 1., 1., 1.],\n",
            "        [1., 1., 0., 0., 1., 1.],\n",
            "        [1., 1., 0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 0., 1.],\n",
            "        [1., 1., 0., 1., 1., 1.]], device='cuda:0')\n",
            "tensor([[ True,  True, False,  True,  True,  True],\n",
            "        [ True, False, False,  True, False,  True],\n",
            "        [ True,  True, False,  True,  True,  True],\n",
            "        [ True,  True, False,  True,  True,  True],\n",
            "        [ True,  True, False, False,  True,  True],\n",
            "        [ True,  True, False,  True,  True,  True],\n",
            "        [False, False,  True,  True, False,  True],\n",
            "        [ True,  True, False,  True,  True,  True]], device='cuda:0')\n",
            "tensor([[0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 0, 1, 0],\n",
            "        [0, 0, 0, 0, 0, 0]], device='cuda:0') tensor([[0., 0., 1., 0., 0., 0.],\n",
            "        [0., 1., 1., 0., 1., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQZAOz1_CoaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70cde8a-3560-4830-a714-914569b3090d"
      },
      "source": [
        "x=np.arange(40).reshape(2,2,10)\n",
        "print(x.shape)\n",
        "print(x[0,:,:],x[1,:,:])\n",
        "print(np.concatenate((x[0,:,:],x[1,:,:]),axis=1).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2, 10)\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]] [[20 21 22 23 24 25 26 27 28 29]\n",
            " [30 31 32 33 34 35 36 37 38 39]]\n",
            "(2, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I9WrOZiPyuR"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from numba import cuda\n",
        "from tqdm import tqdm  "
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uJKKEwu05kn",
        "outputId": "a19a5a1c-848e-430b-fe8d-840f7b0ea238"
      },
      "source": [
        "11//3"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4naqefFBs3u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "3e4e6a80-69d4-4ae9-9ddc-2167014560da"
      },
      "source": [
        "#Now we set our training function \n",
        "def train_model(model, trainloader, valloader, optimizer, num_epochs=9):\n",
        "\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        running_train_loss = 0.0\n",
        "        running_val_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        model.train()\n",
        "        # Iterate over data.\n",
        "        for j,(inputs, labels) in enumerate(trainloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels.float())\n",
        "        \n",
        "                      #running_corrects += torch.sum(preds == labels.data[:,z])\n",
        "                    # backward + optimize only if in training phase\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_train_loss += loss.item()\n",
        "                if j%4000==0:\n",
        "                  model.eval()   \n",
        "                  with torch.no_grad():   \n",
        "                    for val_inp,val_lab in valloader:\n",
        "                      val_out = model(val_inp)\n",
        "                      loss = criterion(val_out, val_lab.float())\n",
        "                      running_val_loss += loss.item() * inputs.size(0)\n",
        "                      preds=torch.where(outputs<0.5,0,1)\n",
        "                      map=((preds==val_lab).float().mean()\n",
        "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloaders.dataset)\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == val and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            model_file = model_name + '/model_' + str(epoch) + '.pth'\n",
        "            print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
        "            print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        " \n",
        "#We define a criterion for the loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#We define an optimizier with the Stochastic Gradient Descent method \n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "#optimizer_ft_2 = optim.SGD(model_ft_2.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        " \n",
        "#And finally we train the model \n",
        "model = train_model(model, criterion, optimizer_ft, num_epochs=10)\n",
        "#model_ft_2 = train_model(model_ft_2, criterion, optimizer_ft_2, num_epochs=10)\n",
        "\n",
        "#For each epoch, we will have the training loss and accuracy, as well as the validation loss and accuracy "
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-117-66a5b2100709>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    if phase == val and epoch_acc > best_acc:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}